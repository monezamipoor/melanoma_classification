# Dataset Arguments
dataset:
  image_size: [224, 224] # Width, Height of input images
  augmentations:
    horizontal_flip: 0.4
    vertical_flip: 0.2
    random_rotation: 10 # degrees
    color_jitter: 0.2 # brightness, contrast, saturation
    image_mix_enabled: True
    image_mix_type: column   # Use "column" to activate ColumnMixTransform.
    image_mix_prob: 0.3   
    random_shear: 10 
    shift_vertical: [0.1, 0.1]

  #oversampling_rate: 1.5  # For imbalanced datasets
  #stratified_batching: true  # For maintaining class distribution in batches
  dataset_train_path: "H:/My Drive/melanoma/melanoma-256-jpg/train"
  dataset_train_csv: "H:/My Drive/melanoma/melanoma-256-jpg/train-small.csv"
  dataset_val_path: "H:/My Drive/melanoma/melanoma-256-jpg/train"
  dataset_test_path: "H:/My Drive/melanoma/melanoma-256-jpg/test"
  batch_size: 32
  # dataset_train_path: "./data/test"
  # k_fold_validation: 5 # Options: k, none
  # test: false # Include test dataset as well or only train and validation
  # add_metadata: false # adding or removing metadata

# Model Arguments
model:
  backbone: "efficientnet_b0" # Options: resnet18, resnet50, efficientnet_b0, vit_base
  pretrained: true
  output_neurons: 1 # Number of classes
  dropout_rate: 0.3
  freeze_backbone: true
  num_frozen_layers: 3
  #focal_loss:
    #gamma: 2.0
    #alpha: 0.25
    #reduction: "mean"

# Training Arguments
training:
  optimizer: "adamw" # Options: adam, sgd, adamw, adagrad, amsgrad
  learning_rate: 0.01
  scheduler: "cosine" # Options: cosine, step, reduce_on_plateau
  decay_rate: 0.1 # For step scheduler
  step_size: 30 # Epochs between decay for step scheduler

  epochs: 3

  warmup_epochs: 0
  freeze_pretrained: true # Whether to freeze backbone layers
  mixed_precision: false # Whether to use mixed precision training
  gradient_clipping: 1.0

# Testing and Logging Arguments
testing:
  log_dir: "./logs"   # YAML-TIMESTAMP gets created under here
  model_save_strategy: "best" # Options: all, best, last, none
  model_save_metrics: ["AUC", "Recall"]
  model_metrics: ["AUC","Accuracy","F1 Score", "Precision", "Recall"]
  checkpoint_dir: "./checkpoints"   # creates this as a sub-dir under each run
  wandb:
    project_name: #"melanoma-playpen" # yourproject
    entity: #"jc03172-university-of-surrey" # yourorg
    api_key: #"ec4f88fbbc7df980f677f5b76580d03e52373b6e" # Replace with your actual key
  early_stopping:
    patience: 10
    min_delta: 0.001
