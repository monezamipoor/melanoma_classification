# Dataset Arguments
dataset:
  image_size: [224, 224] # Width, Height of input images
  augmentations:
    horizontal_flip: 0.4
    vertical_flip: 0.2
    random_rotation: 10 # degrees
    color_jitter: 0.2 # brightness, contrast, saturation
    image_mix_enabled: True
    image_mix_type: column   # Use "column" to activate ColumnMixTransform.
    image_mix_prob: 0.3   
    random_shear: 10 
    shift_vertical: [0.1, 0.1]

  #oversampling_rate: 1.5  # For imbalanced datasets
  #stratified_batching: true  # For maintaining class distribution in batches
  dataset_train_path: "/content/Melanoma/train"

  dataset_train_csv: "/content/drive/MyDrive/melanoma_classification/train-small.csv"

  dataset_val_path: "/content/Melanoma/train"
  dataset_test_path: "/content/Melanoma/test"
  batch_size: 16
  # dataset_train_path: "./data/test"
  # k_fold_validation: 5 # Options: k, none
  # test: false # Include test dataset as well or only train and validation
  # add_metadata: false # adding or removing metadata

# Model Arguments
model:
  backbone: "resnet50" # Options: resnet18, resnet50, efficientnet_b0, vit_base
  pretrained: true
  output_neurons: 1 # Number of classes
  dropout_rate: 0.3
  freeze_backbone: true
  num_frozen_layers: 3
  focal_loss:
    gamma: 2.0
    alpha: 0.25
    reduction: "mean"

# Training Arguments
training:
  optimizer: "amsgrad" # Options: adam, sgd, adamw, adagrad, amsgrad
  learning_rate: 0.001
  scheduler: "cosine" # Options: cosine, step, reduce_on_plateau
  decay_rate: 0.1 # For step scheduler
  step_size: 30 # Epochs between decay for step scheduler

  epochs: 35

  warmup_epochs: 5
  freeze_pretrained: true # Whether to freeze backbone layers
  mixed_precision: false # Whether to use mixed precision training
  gradient_clipping: 1.0

# Testing and Logging Arguments
testing:
  log_dir: "./logs"   # YAML-TIMESTAMP gets created under here
  model_save_strategy: "best" # Options: all, best, last, none
  model_save_metrics: ["AUC"]
  model_metrics: ["AUC","Accuracy","F1 Score", "Precision", "Recall"]
  checkpoint_dir: "./checkpoints"   # creates this as a sub-dir under each run
  wandb:
    project_name: # yourproject
    entity: # yourorg
    api_key: # Replace with your actual key
  early_stopping:
    patience: 10
    min_delta: 0.001
